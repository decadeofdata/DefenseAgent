{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# DefenceAgent for Analyzing Defense-Related Text or Files\n## Description:\nThis notebook creates an AI agent (DefenceAgent) to analyze text input or uploaded files for defense insights. The extension of this project would be to create an AI Defence Agent to analyse military documents. \n\n## Techniques Used: \nStructured Output (JSON mode), Few-shot Prompting, Retrieval Augmented Generation (RAG), AI agent. \n\n## Input: \nText input or file (e.g., text file, CSV) containing defense-related data\nNote: Optimized for Kaggle with error handling and minimal dependenciesv\n\n### Project roadblock:\nDespite the code working, I kept getting errors in loading data from Kaggle or uploading data. So I had to use dummy data instead. In theory this can be applied to other Kaggle Notebooks.  ","metadata":{}},{"cell_type":"markdown","source":"## Installing libraries","metadata":{}},{"cell_type":"code","source":"# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:55.865146Z","iopub.execute_input":"2025-04-18T13:01:55.865515Z","iopub.status.idle":"2025-04-18T13:01:55.872223Z","shell.execute_reply.started":"2025-04-18T13:01:55.865491Z","shell.execute_reply":"2025-04-18T13:01:55.871121Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nimport json\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:55.874727Z","iopub.execute_input":"2025-04-18T13:01:55.875003Z","iopub.status.idle":"2025-04-18T13:01:55.893244Z","shell.execute_reply.started":"2025-04-18T13:01:55.874982Z","shell.execute_reply":"2025-04-18T13:01:55.892297Z"}},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":"## Step 1: Read the file or not","metadata":{}},{"cell_type":"code","source":"def read_file(file_path):\n    \"\"\"Read text from a file (text or CSV).\"\"\"\n    try:\n        if file_path.endswith('.txt'):\n            with open(file_path, 'r', encoding='utf-8') as f:\n                return f.read()\n        elif file_path.endswith('.csv'):\n            df = pd.read_csv(file_path)\n            # Assume text is in a 'text' column; adjust as needed\n            return ' '.join(df['text'].dropna().astype(str))\n        else:\n            return \"Unsupported file format. Please provide a .txt or .csv file.\"\n    except Exception as e:\n        return f\"Error reading file: {str(e)}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:55.900590Z","iopub.execute_input":"2025-04-18T13:01:55.900974Z","iopub.status.idle":"2025-04-18T13:01:55.920061Z","shell.execute_reply.started":"2025-04-18T13:01:55.900941Z","shell.execute_reply":"2025-04-18T13:01:55.918932Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"from io import StringIO","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:55.921840Z","iopub.execute_input":"2025-04-18T13:01:55.922172Z","iopub.status.idle":"2025-04-18T13:01:55.943625Z","shell.execute_reply.started":"2025-04-18T13:01:55.922148Z","shell.execute_reply":"2025-04-18T13:01:55.942247Z"}},"outputs":[],"execution_count":54},{"cell_type":"markdown","source":"## Step 2: Load or Create Dummy Dataset\n<p>Check for uploaded dataset in Kaggle's input directory.</p>\n<p>If text colomn not found then use dummy data.</p>","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/Radar_Traffic_Counts.csv'  # Adjust to your dataset\ntry:\n    df = pd.read_csv(data_path)\n    if 'text' not in df.columns:\n        raise ValueError(\"Dataset must have a 'text' column.\")\nexcept (FileNotFoundError, ValueError) as e:\n    print(f\"Dataset error: {str(e)}. Using dummy data for demonstration.\")\n    # Create dummy defense reports data\n    np.random.seed(42)\n    df = pd.DataFrame({\n        'report_id': [f'REPORT_{i}' for i in range(500)],\n        'text': [\n            'Suspicious activity detected near military base.' if i % 3 == 0 else\n            'Routine patrol, no incidents reported.' if i % 3 == 1 else\n            'Rocket attack.' if i % 3 == 2 else\n            'Potential threat identified in communication intercept.' for i in range(500)\n        ],\n        'location': np.random.choice(['Base Alpha', 'City Beta', 'Unknown'], 500),\n        'timestamp': pd.date_range('2025-01-01', periods=500, freq='H')\n    })\n\n# Display dataset info\nprint(\"Dataset Info:\")\nprint(df.info())\nprint(\"\\nSample Data:\")\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:55.974866Z","iopub.execute_input":"2025-04-18T13:01:55.975410Z","iopub.status.idle":"2025-04-18T13:01:55.997719Z","shell.execute_reply.started":"2025-04-18T13:01:55.975350Z","shell.execute_reply":"2025-04-18T13:01:55.996346Z"}},"outputs":[{"name":"stdout","text":"Dataset error: [Errno 2] No such file or directory: '/kaggle/input/Radar_Traffic_Counts.csv'. Using dummy data for demonstration.\nDataset Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 500 entries, 0 to 499\nData columns (total 4 columns):\n #   Column     Non-Null Count  Dtype         \n---  ------     --------------  -----         \n 0   report_id  500 non-null    object        \n 1   text       500 non-null    object        \n 2   location   500 non-null    object        \n 3   timestamp  500 non-null    datetime64[ns]\ndtypes: datetime64[ns](1), object(3)\nmemory usage: 15.8+ KB\nNone\n\nSample Data:\n  report_id                                              text    location  \\\n0  REPORT_0  Suspicious activity detected near military base.     Unknown   \n1  REPORT_1            Routine patrol, no incidents reported.  Base Alpha   \n2  REPORT_2                                    Rocket attack.     Unknown   \n3  REPORT_3  Suspicious activity detected near military base.     Unknown   \n4  REPORT_4            Routine patrol, no incidents reported.  Base Alpha   \n\n            timestamp  \n0 2025-01-01 00:00:00  \n1 2025-01-01 01:00:00  \n2 2025-01-01 02:00:00  \n3 2025-01-01 03:00:00  \n4 2025-01-01 04:00:00  \n","output_type":"stream"}],"execution_count":55},{"cell_type":"markdown","source":"## Step 3: Train a text classifier ","metadata":{}},{"cell_type":"code","source":"try:\n    # Label reports as 'threat' or 'non-threat' (keyword-based for demo)\n    df['label'] = df['text'].str.contains('suspicious|threat', case=False, na=False).astype(int)  # 1 = threat, 0 = non-threat\n\n    # Extract features using TF-IDF\n    vectorizer = TfidfVectorizer(max_features=500)\n    X = vectorizer.fit_transform(df['text'])\n    y = df['label']\n\n    # Split data\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    # Train Logistic Regression classifier\n    clf = LogisticRegression(random_state=42)\n    clf.fit(X_train, y_train)\n\n    # Evaluate\n    y_pred = clf.predict(X_test)\n    print(\"\\nClassifier Performance:\")\n    print(classification_report(y_test, y_pred))\nexcept Exception as e:\n    print(f\"Error training classifier: {str(e)}\")\n    # Fallback: Initialize a dummy classifier\n    clf = LogisticRegression()\n    vectorizer = TfidfVectorizer(max_features=500)\n    X = vectorizer.fit_transform(['dummy text'])\n    clf.fit(X, [0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:56.005087Z","iopub.execute_input":"2025-04-18T13:01:56.005446Z","iopub.status.idle":"2025-04-18T13:01:56.053024Z","shell.execute_reply.started":"2025-04-18T13:01:56.005419Z","shell.execute_reply":"2025-04-18T13:01:56.050343Z"}},"outputs":[{"name":"stdout","text":"\nClassifier Performance:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        68\n           1       1.00      1.00      1.00        32\n\n    accuracy                           1.00       100\n   macro avg       1.00      1.00      1.00       100\nweighted avg       1.00      1.00      1.00       100\n\n","output_type":"stream"}],"execution_count":56},{"cell_type":"markdown","source":"## Step 4: Implement Retrieval Augmented Generation (RAG)\n<p>Technique: Retrieval Augmented Generation (RAG).</p>\n<p>Use TF-IDF cosine similarity to retrieve relevant defense profiles (avoids PyTorch/FAISS to avoid errors). It modifies interactions with a large language model so that the model responds to user queries with reference to a specified set of documents.</p>\n","metadata":{}},{"cell_type":"code","source":"# Create a knowledge base with defense-related profiles\nknowledge_base = [\n    \"Suspicious activity near military bases often indicates reconnaissance or sabotage.\",\n    \"Routine patrols with no incidents suggest stable security conditions.\",\n    \"Communication intercepts mentioning threats may involve coded language or planning.\",\n    \"Possible insurgent activity.\",\n    \"Potentially hostile situation with a foreign entity.\"\n]\n\n# Initialize TF-IDF vectorizer for knowledge base\nkb_vectorizer = TfidfVectorizer()\nkb_vectors = kb_vectorizer.fit_transform(knowledge_base)\n\ndef retrieve_relevant_info(query, k=2):\n    \"\"\"Retrieve top-k relevant profiles using TF-IDF cosine similarity.\"\"\"\n    try:\n        query_vector = kb_vectorizer.transform([query])\n        cosine_similarities = (kb_vectors @ query_vector.T).toarray().flatten()\n        top_k_indices = np.argsort(cosine_similarities)[-k:][::-1]\n        return [knowledge_base[idx] for idx in top_k_indices]\n    except Exception as e:\n        print(f\"Error in retrieval: {str(e)}\")\n        return knowledge_base[:k]  # Fallback: Return first k items\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:56.078590Z","iopub.execute_input":"2025-04-18T13:01:56.079011Z","iopub.status.idle":"2025-04-18T13:01:56.103687Z","shell.execute_reply.started":"2025-04-18T13:01:56.078978Z","shell.execute_reply":"2025-04-18T13:01:56.101053Z"}},"outputs":[],"execution_count":57},{"cell_type":"markdown","source":"## Step 5: Define DefenceAgent Class\n<p>Technique: Structured Output (JSON mode).</p>\n<p>Technique: Few-shot Prompting. Few-shot prompting is a technique in artificial intelligence where a model is given a small number of examples to learn from before generating a response. This method helps improve the model's performance on specific tasks by guiding it with relevant demonstrations.</p>","metadata":{}},{"cell_type":"code","source":"class DefenceAgent:\n    def __init__(self, classifier, vectorizer, kb_vectorizer, knowledge_base):\n        self.classifier = classifier\n        self.vectorizer = vectorizer\n        self.kb_vectorizer = kb_vectorizer\n        self.knowledge_base = knowledge_base\n\n    def analyze_input(self, input_data, input_type='text', file_path=None):\n        \"\"\"Analyze text input or file and return structured output.\"\"\"\n        try:\n            # Handle input type\n            if input_type == 'text':\n                text = input_data\n                input_id = \"TEXT_INPUT\"\n            elif input_type == 'file' and file_path:\n                text = read_file(file_path)\n                input_id = os.path.basename(file_path) if file_path else \"UNKNOWN_FILE\"\n            else:\n                return json.dumps({\"error\": \"Invalid input type or missing file path\"}, indent=2)\n\n            if \"Error\" in text or \"Unsupported\" in text:\n                return json.dumps({\"error\": text}, indent=2)\n\n            # Predict threat level\n            text_vector = self.vectorizer.transform([text])\n            prediction = self.classifier.predict(text_vector)[0]\n            confidence = self.classifier.predict_proba(text_vector)[0][prediction]\n            threat_label = 'threat' if prediction == 1 else 'non-threat'\n\n            # --- Few-shot Prompting ---\n            # Provide examples to guide the analysis\n            few_shot_examples = \"\"\"\n            Example 1:\n            Input: Suspicious activity detected near military base.\n            Output: Threat detected, possible reconnaissance activity.\n\n            Example 2:\n            Input: Routine patrol, no incidents reported.\n            Output: No threat detected, normal operations.\n\n            Input: {text}\n            Output:\n            \"\"\"\n            prompt = few_shot_examples.format(text=text[:100])  # Truncate for brevity\n\n            # --- RAG: Retrieve relevant information ---\n            retrieved_info = retrieve_relevant_info(text)\n\n            # Generate analysis\n            analysis = f\"Classified as {threat_label}. {retrieved_info[0]}\"\n\n            # --- Structured Output (JSON mode) ---\n            output = {\n                \"input_id\": input_id,\n                \"threat_level\": threat_label,\n                \"confidence\": float(confidence),\n                \"analysis\": analysis,\n                \"retrieved_context\": retrieved_info\n            }\n            return json.dumps(output, indent=2)\n        except Exception as e:\n            return json.dumps({\"error\": f\"Analysis failed: {str(e)}\"}, indent=2)\n\n# Initialize the DefenceAgent\nagent = DefenceAgent(clf, vectorizer, kb_vectorizer, knowledge_base)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:56.106744Z","iopub.execute_input":"2025-04-18T13:01:56.107227Z","iopub.status.idle":"2025-04-18T13:01:56.137103Z","shell.execute_reply.started":"2025-04-18T13:01:56.107191Z","shell.execute_reply":"2025-04-18T13:01:56.133773Z"}},"outputs":[],"execution_count":58},{"cell_type":"markdown","source":"## Step 6: Test the DefenceAgent \n<p>End result is an AI Defence Agent that analyses reports to assess threat and confidence levels.</p>","metadata":{}},{"cell_type":"code","source":"test_text = \"Suspicious activity detected near military base.\"\nprint(\"\\nText Input Analysis:\")\nprint(agent.analyze_input(test_text, input_type='text'))\n\n# Test with a file (create a dummy file for demo)\ndummy_file_path = '/kaggle/working/test_report.txt'\ntry:\n    with open(dummy_file_path, 'w') as f:\n        f.write(\"Potential threat identified in communication intercept.\")\n    print(\"\\nFile Input Analysis:\")\n    print(agent.analyze_input(None, input_type='file', file_path=dummy_file_path))\nexcept Exception as e:\n    print(f\"Error testing file input: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:56.138769Z","iopub.execute_input":"2025-04-18T13:01:56.139344Z","iopub.status.idle":"2025-04-18T13:01:56.162318Z","shell.execute_reply.started":"2025-04-18T13:01:56.139310Z","shell.execute_reply":"2025-04-18T13:01:56.161265Z"}},"outputs":[{"name":"stdout","text":"\nText Input Analysis:\n{\n  \"input_id\": \"TEXT_INPUT\",\n  \"threat_level\": \"threat\",\n  \"confidence\": 0.964086462094688,\n  \"analysis\": \"Classified as threat. Suspicious activity near military bases often indicates reconnaissance or sabotage.\",\n  \"retrieved_context\": [\n    \"Suspicious activity near military bases often indicates reconnaissance or sabotage.\",\n    \"Possible insurgent activity.\"\n  ]\n}\n\nFile Input Analysis:\n{\n  \"input_id\": \"test_report.txt\",\n  \"threat_level\": \"non-threat\",\n  \"confidence\": 0.8261336713975911,\n  \"analysis\": \"Classified as non-threat. Communication intercepts mentioning threats may involve coded language or planning.\",\n  \"retrieved_context\": [\n    \"Communication intercepts mentioning threats may involve coded language or planning.\",\n    \"Potentially hostile situation with a foreign entity.\"\n  ]\n}\n","output_type":"stream"}],"execution_count":59},{"cell_type":"markdown","source":"## Step 7: Save the model and Knowledge Base","metadata":{}},{"cell_type":"code","source":"try:\n    import joblib\n    joblib.dump(clf, '/kaggle/working/defence_classifier.pkl')\n    joblib.dump(vectorizer, '/kaggle/working/vectorizer.pkl')\n    joblib.dump(kb_vectorizer, '/kaggle/working/kb_vectorizer.pkl')\n    with open('/kaggle/working/knowledge_base.json', 'w') as f:\n        json.dump(knowledge_base, f)\n    print(\"\\nModel and knowledge base saved successfully.\")\nexcept Exception as e:\n    print(f\"Error saving model: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T13:01:56.163364Z","iopub.execute_input":"2025-04-18T13:01:56.163878Z","iopub.status.idle":"2025-04-18T13:01:56.192842Z","shell.execute_reply.started":"2025-04-18T13:01:56.163849Z","shell.execute_reply":"2025-04-18T13:01:56.191824Z"}},"outputs":[{"name":"stdout","text":"\nModel and knowledge base saved successfully.\n","output_type":"stream"}],"execution_count":60}]}